remark: eval_test_v2
model_type: qwen3
model_name: Qwen/Qwen3-4B-Instruct-2507

dataset_name: gsm8k
train_samples: 30  # Increased from 20
test_samples: 20    # Increased from 10
dataloader_seed: 42

learning_rate: 5e-5  # Increased from 1e-5
batch_size: 1
num_epochs: 100  # Reduced from 50 for faster iteration
gradient_accumulation_steps: 4

num_generations: 4
max_prompt_length: 256
max_generate_length: 256
temperature: 0.8 
eval_temperature: 0.3
beta: 0.05  # Added KL regularization (was 0.0)
clip_eps: 0.2

load_in_4bit: true
compute_dtype: bfloat16
use_flash_attention: true
use_gradient_checkpointing: true
device_map: auto

use_wandb: true
wandb_project: qwen3_4b_grpo

output_dir: /home/hula0401/learning_llm/training_with_unsloth/output/eval_test_v2
logs_dir: /home/hula0401/learning_llm/training_with_unsloth/logs/eval_test_v2

random_seed: 42

